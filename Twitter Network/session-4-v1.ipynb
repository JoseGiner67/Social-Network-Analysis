{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 04: Networks from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Jose Giner</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">joseginer67@gmail.com</font>\n",
    "\n",
    "Date: <font color=\"blue\">22/02/2022</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the directed mention network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Input file\n",
    "COMPRESSED_INPUT_FILENAME = \"data/CovidLockdownCatalonia.json.gz\"\n",
    "\n",
    "# These are the output files, leave as-is\n",
    "OUTPUT_ALL_EDGES_FILENAME = \"data/CovidLockdownCatalonia.csv\"\n",
    "OUTPUT_FILTERED_EDGES_FILENAME = \"data/CovidLockdownCatalonia-min-weight-filtered.csv\"\n",
    "OUTPUT_CO_MENTIONS_FILENAME = \"data/CovidLockdownCatalonia-co-mentions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extract mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jordi', 'Xavier']\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def extract_mentions(text):\n",
    "    return re.findall(\"@([a-zA-Z0-9_]{5,20})\", text)\n",
    "\n",
    "print(extract_mentions(\"RT @Jordi: check this post by @Xavier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Count mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to read the compressed input file and create the mentions_counter dictionary.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(COMPRESSED_INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    mentions_counter = {}\n",
    "    for line in input_file:\n",
    "        tweet = json.loads(line)\n",
    "        author = tweet[\"user\"][\"screen_name\"]\n",
    "        message = tweet[\"full_text\"]\n",
    "        mentions = extract_mentions(message)\n",
    "        for m in mentions:\n",
    "            key = (author,m)\n",
    "            if key in mentions_counter:\n",
    "                mentions_counter[key] += 1\n",
    "            else:\n",
    "                mentions_counter[key] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_counter[('joanmariapique','catalangov')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "with io.open(OUTPUT_ALL_EDGES_FILENAME, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter='\\t', quotechar='\"', lineterminator='\\n')\n",
    "    writer.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    for key in mentions_counter:\n",
    "        author = key[0]\n",
    "        mention = key[1]\n",
    "        weight = mentions_counter[key]\n",
    "        writer.writerow([author, mention, weight])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edges = pd.read_csv(OUTPUT_ALL_EDGES_FILENAME, sep = '\\t')\n",
    "edges = edges.drop(edges[edges.Weight < 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XaviMarti5</td>\n",
       "      <td>XSalaimartin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>EnriqueTgn</td>\n",
       "      <td>vpartal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mjorubiomari</td>\n",
       "      <td>elnacionalcat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>baco8baco</td>\n",
       "      <td>Gargotejant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ERoigM</td>\n",
       "      <td>marfanta</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source         Target  Weight\n",
       "7     XaviMarti5   XSalaimartin       2\n",
       "50    EnriqueTgn        vpartal       2\n",
       "83  mjorubiomari  elnacionalcat       2\n",
       "93     baco8baco    Gargotejant       2\n",
       "97        ERoigM       marfanta       2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.to_csv(OUTPUT_FILTERED_EDGES_FILENAME, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the directed mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mentions graph](mentions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is composed of several components, where there is a larger one at the top that contains some nodes with a high in-degree centrality (greater size), that represent popular actors like the government, newspaper or health services of Catalonia. Also, there are many small disconnected components, that may ilustrate casual friend mentions. The largest component contais 699 nodes out of 1600 that are in total, about a 43%. The second largest component contains 16 nodes, composing a 1% of the total nodes in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mentions graph largest connected component](mentions-largest-cc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mentions in-degree distribution](mentions-in-degree-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mentions out-degree distribution](mentions-out-degree-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the largest component, we can see a scale-free graph with more attachments to nodes with higher degree often called hubs. With the node groups created from the affinity propagation clustering, it is clearly appreciated how all those nodes or users who mention to the same high degree node, belong to the same group. There are some cases where the node acting as a hub belongs to a group different than the one containing all less popular nodes who are pointing to such node. \n",
    "\n",
    "In these two node degree distributions, we can see that both of them follow a Power Law distribution. From the in-degree graph, we can see that most of the nodes have zero incoming edges which are users who are not being mentioned by other user accounts and the high centrality nodes are the few ones with higher in-degree value. As said before, these represent official services, government and politicians of the Catalonia region that were the centre of attention back in the pandemic days. From the out-degree graph, a similar behaviour occurs, as there are many nodes with low out-degree (lots of users who didnÂ´t mention others) and few of them have high out-degree, that are casual users who mentioned many of other users that day.\n",
    "\n",
    "It is interesting to see that the diameter of this largest component is of 20 (high value in my opinion and relevant because lots of interconnections are needed to travel from one node to another in some cases despite hubs having a high betweenness centrality) and a characteristic path length of almost 6 that supports the small world theory in these types of networks as the average distance follows log(N), with N = 699.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create the undirected co-mention network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(COMPRESSED_INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    co_mentions_counter = {}\n",
    "    for line in input_file:\n",
    "        tweet = json.loads(line)\n",
    "        message = tweet[\"full_text\"]\n",
    "        mentions = extract_mentions(message)\n",
    "        for i in range(len(mentions)-1):\n",
    "            for j in range(i+1,len(mentions)):\n",
    "                tup = (mentions[i],mentions[j])\n",
    "                key = tuple(sorted(tup))\n",
    "                \n",
    "                if key in co_mentions_counter:\n",
    "                    co_mentions_counter[key] += 1\n",
    "                else:\n",
    "                    co_mentions_counter[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "key = ('agriculturacat', 'uniopagesos')\n",
    "print(co_mentions_counter[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(OUTPUT_CO_MENTIONS_FILENAME, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter='\\t', quotechar='\"', lineterminator='\\n')\n",
    "    writer.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    for key in co_mentions_counter:\n",
    "        user1 = key[0]\n",
    "        user2 = key[1]\n",
    "        weight = co_mentions_counter[key]\n",
    "        writer.writerow([user1, user2, weight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Co-mentions graph](co-mentions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in to the largest component:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Co-mentions largest component](co-mentions-largest-comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the co-mentions graph, we can see that it contains several components and one of them is the largest of all, which has 1514 nodes out of the 4044 that are in total (a 37%). The secondary components are in most of the cases highly interconnected or complete subgraphs, suggesting that these reprent users who are only mentioned all together in the same tweet. This is also appreciated in the largest component, where there exists high densely connected parts but this time some users appear in mentions with others not beloning to this zone, enabling a path to the rest of the component. \n",
    "\n",
    "Looking at the degree distribution, we can see that this largest component follows a Power Law distribution proper of scale free networks and there are lots of nodes having a degree less than the average degree. The high centrality nodes are located at the central spot of the component, being those user accounts that have been mentioned together with many other users. For example, Catalonia government, health authorities or politicians. As more followers an account has, it is expected to be mentioned together with more users. From the stats of the network analyzer, we can see a small characteristic path length of 5.4 so the average distance between nodes is not that large, a clustering coeficient of 0.5 meaning that in average half of the total possible edges that connect neighbours of a node are present and this supports the small world phenomenon in these types of networks. In this case, the average degree is not very informative due to the 'long tail' in the degree distribution, where the high degree nodes produce a high variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, text, and figures were produced by myself.</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
